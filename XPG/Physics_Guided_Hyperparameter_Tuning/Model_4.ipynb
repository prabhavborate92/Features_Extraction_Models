{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XGCve0bhxHd"
      },
      "outputs": [],
      "source": [
        "# Load libraries\n",
        "import math\n",
        "import sys\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.fft import fft, ifft\n",
        "from scipy import interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy import signal\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.models import Sequential,  Model\n",
        "from keras.layers import Dense, LSTM, TimeDistributed, Flatten, Bidirectional, Input\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from keras.layers import MaxPooling2D, Conv2D, MaxPooling1D, Conv1D, Dense, Flatten, AveragePooling1D, LSTM, Dropout, Input, Concatenate, LeakyReLU, BatchNormalization, Activation\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from google.colab import files\n",
        "from numpy import savetxt\n",
        "from keras.layers import Layer\n",
        "from xgboost import XGBRegressor\n",
        "from matplotlib import pyplot\n",
        "np.random.seed(0)\n",
        "tf.random.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UB8SOSYBh2OH",
        "outputId": "c021d1f9-3021-4085-9854-6b7e5bfd6a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "data1 = loadmat('/content/drive/My Drive/Colab Notebooks/Final_Features_Extraction_Codes/XPG/Physics_Guided_WA_No_Regularizer/Input_Output_Data_XPG_No_Reg.mat')\n",
        "df = pd.DataFrame({'F1':data1['F1'].flatten().round(2),'SS':data1['SS'].flatten()})\n",
        "df = df[['F1','SS']]"
      ],
      "metadata": {
        "id": "MWa4Rtnlh-_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function: Create Data History\n",
        "def create_timesteps(data, n_steps):\n",
        "\tx = []\n",
        "\ty = []\n",
        "\tfor i in range(len(data)-1):\n",
        "\t\tend_ix = i + n_steps\n",
        "\t\tif end_ix > len(data)-1:\n",
        "\t\t\tbreak\n",
        "\t\tx1, y1 = data[i:end_ix, :-1], data[end_ix, -1]\n",
        "\t\tx.append(x1)\n",
        "\t\ty.append(y1)\n",
        "\treturn np.array(x), np.array(y)"
      ],
      "metadata": {
        "id": "h5vfBgz0l4j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing (SS)\n",
        "arr = df.to_numpy()\n",
        "n_steps = 300\n",
        "xdf, ydf_SS = create_timesteps(arr, n_steps)\n",
        "\n",
        "# Reshape\n",
        "in_dim = xdf.shape[1]*xdf.shape[2]\n",
        "xdf = xdf.reshape((xdf.shape[0], in_dim))"
      ],
      "metadata": {
        "id": "DtAHOd5ti5XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train-val-test (SS)\n",
        "x_train, x_test, y_train_SS, y_test_SS = train_test_split(xdf, ydf_SS, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, Y_train_SS, Y_val_SS = train_test_split(x_train, y_train_SS, test_size=0.125, shuffle=False)\n",
        "\n",
        "# Normalize the input\n",
        "scaler = MinMaxScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train))\n",
        "X_val = pd.DataFrame(scaler.transform(X_val))\n",
        "x_test = pd.DataFrame(scaler.transform(x_test))"
      ],
      "metadata": {
        "id": "r-d2oomEjCj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define DD\n",
        "def MLP_Data():\n",
        "\n",
        "    # Define inputs\n",
        "    X_train = layers.Input(shape=(n_steps,),name='X_train')\n",
        "\n",
        "    # Prediction: Shear Stress + Slip Rate\n",
        "    x = layers.Dense(128,kernel_initializer = 'normal', activation=\"relu\")(X_train)\n",
        "    x = layers.Dense(64,kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "    x = layers.Dense(32,kernel_initializer = 'normal', activation=\"relu\")(x)\n",
        "    ss_pred = layers.Dense(1,kernel_initializer = 'normal',activation=\"linear\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=[X_train],outputs=[ss_pred])\n",
        "    return model"
      ],
      "metadata": {
        "id": "RsONpQH3jT22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP_Data()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "s29UGjtsjXRa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "520b1c6a-4c15-454d-b3d4-6532f218638c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ X_train (\u001b[38;5;33mInputLayer\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m38,528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ X_train (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">38,528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m48,897\u001b[0m (191.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,897</span> (191.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,897\u001b[0m (191.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,897</span> (191.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile & Run\n",
        "model=MLP_Data()\n",
        "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(1e-3), metrics=['mse'])\n",
        "\n",
        "earlystop = EarlyStopping(monitor='val_loss', min_delta=0, patience=20,verbose=1, mode='auto')\n",
        "checkpoint = ModelCheckpoint('/content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [earlystop, checkpoint]\n",
        "history = model.fit([X_train],[Y_train_SS], epochs=100, batch_size=32,callbacks=callbacks_list,\n",
        "                     validation_data=([X_val],[Y_val_SS]), verbose=1)\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='val')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0W_VB69ZjZzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a65ae25e-1f60-4c49-a067-700006780ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m2168/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9449 - mse: 1.9449\n",
            "Epoch 1: val_loss improved from inf to 0.09597, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 1.9358 - mse: 1.9358 - val_loss: 0.0960 - val_mse: 0.0960\n",
            "Epoch 2/100\n",
            "\u001b[1m2166/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0467 - mse: 0.0467\n",
            "Epoch 2: val_loss improved from 0.09597 to 0.00168, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0465 - mse: 0.0465 - val_loss: 0.0017 - val_mse: 0.0017\n",
            "Epoch 3/100\n",
            "\u001b[1m2173/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035\n",
            "Epoch 3: val_loss improved from 0.00168 to 0.00161, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0035 - mse: 0.0035 - val_loss: 0.0016 - val_mse: 0.0016\n",
            "Epoch 4/100\n",
            "\u001b[1m2179/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0033 - mse: 0.0033\n",
            "Epoch 4: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0033 - mse: 0.0033 - val_loss: 0.0019 - val_mse: 0.0019\n",
            "Epoch 5/100\n",
            "\u001b[1m2178/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031\n",
            "Epoch 5: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0031 - mse: 0.0031 - val_loss: 0.0026 - val_mse: 0.0026\n",
            "Epoch 6/100\n",
            "\u001b[1m2165/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0030 - mse: 0.0030\n",
            "Epoch 6: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0030 - mse: 0.0030 - val_loss: 0.0033 - val_mse: 0.0033\n",
            "Epoch 7/100\n",
            "\u001b[1m2165/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0029 - mse: 0.0029\n",
            "Epoch 7: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0029 - mse: 0.0029 - val_loss: 0.0053 - val_mse: 0.0053\n",
            "Epoch 8/100\n",
            "\u001b[1m2175/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0027 - mse: 0.0027\n",
            "Epoch 8: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0027 - mse: 0.0027 - val_loss: 0.0057 - val_mse: 0.0057\n",
            "Epoch 9/100\n",
            "\u001b[1m2178/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.0026\n",
            "Epoch 9: val_loss did not improve from 0.00161\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - loss: 0.0026 - mse: 0.0026 - val_loss: 0.0025 - val_mse: 0.0025\n",
            "Epoch 10/100\n",
            "\u001b[1m2178/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023\n",
            "Epoch 10: val_loss improved from 0.00161 to 0.00097, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 9.6821e-04 - val_mse: 9.6821e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m2166/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0023 - mse: 0.0023\n",
            "Epoch 11: val_loss did not improve from 0.00097\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0023 - mse: 0.0023 - val_loss: 0.0010 - val_mse: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m2175/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0021 - mse: 0.0021\n",
            "Epoch 12: val_loss did not improve from 0.00097\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0021 - mse: 0.0021 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 13/100\n",
            "\u001b[1m2178/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020\n",
            "Epoch 13: val_loss did not improve from 0.00097\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0020 - mse: 0.0020 - val_loss: 0.0032 - val_mse: 0.0032\n",
            "Epoch 14/100\n",
            "\u001b[1m2165/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0019 - mse: 0.0019\n",
            "Epoch 14: val_loss did not improve from 0.00097\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0019 - mse: 0.0019 - val_loss: 0.0023 - val_mse: 0.0023\n",
            "Epoch 15/100\n",
            "\u001b[1m2163/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0018 - mse: 0.0018\n",
            "Epoch 15: val_loss did not improve from 0.00097\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 16/100\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0018 - mse: 0.0018\n",
            "Epoch 16: val_loss improved from 0.00097 to 0.00078, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0018 - mse: 0.0018 - val_loss: 7.8435e-04 - val_mse: 7.8435e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m2176/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mse: 0.0017\n",
            "Epoch 17: val_loss did not improve from 0.00078\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0017 - mse: 0.0017 - val_loss: 8.5825e-04 - val_mse: 8.5825e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m2160/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
            "Epoch 18: val_loss improved from 0.00078 to 0.00074, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 7.3923e-04 - val_mse: 7.3923e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m2166/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mse: 0.0016\n",
            "Epoch 19: val_loss improved from 0.00074 to 0.00073, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0016 - mse: 0.0016 - val_loss: 7.2848e-04 - val_mse: 7.2848e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m2161/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.0015\n",
            "Epoch 20: val_loss improved from 0.00073 to 0.00069, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.8848e-04 - val_mse: 6.8848e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m2172/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015\n",
            "Epoch 21: val_loss improved from 0.00069 to 0.00068, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.8092e-04 - val_mse: 6.8092e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m2167/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mse: 0.0015\n",
            "Epoch 22: val_loss improved from 0.00068 to 0.00068, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0015 - mse: 0.0015 - val_loss: 6.7717e-04 - val_mse: 6.7717e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m2177/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 23: val_loss improved from 0.00068 to 0.00067, saving model to /content/drive/My Drive/Colab Notebooks/p5270/Automatic_Physics_Based_Features_Extraction/Check.keras\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 6.7080e-04 - val_mse: 6.7080e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m2177/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 24: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.0300e-04 - val_mse: 7.0300e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m2162/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 25: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.3937e-04 - val_mse: 7.3937e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m2173/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 26: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 7.7405e-04 - val_mse: 7.7405e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m2177/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 27: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 8.2561e-04 - val_mse: 8.2561e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m2165/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 28: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 9.0814e-04 - val_mse: 9.0814e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m2169/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 29: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 9.2267e-04 - val_mse: 9.2267e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m2172/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 30: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 9.9361e-04 - val_mse: 9.9361e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m2166/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mse: 0.0014\n",
            "Epoch 31: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0014 - mse: 0.0014 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 32/100\n",
            "\u001b[1m2175/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 32: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0012 - val_mse: 0.0012\n",
            "Epoch 33/100\n",
            "\u001b[1m2170/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 33: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0011 - val_mse: 0.0011\n",
            "Epoch 34/100\n",
            "\u001b[1m2174/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 34: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 35/100\n",
            "\u001b[1m2161/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 35: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 36/100\n",
            "\u001b[1m2168/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 36: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 37/100\n",
            "\u001b[1m2170/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 37: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 38/100\n",
            "\u001b[1m2166/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 38: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 39/100\n",
            "\u001b[1m2171/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 39: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 40/100\n",
            "\u001b[1m2169/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 40: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 41/100\n",
            "\u001b[1m2175/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 41: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0014 - val_mse: 0.0014\n",
            "Epoch 42/100\n",
            "\u001b[1m2178/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 42: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0013 - val_mse: 0.0013\n",
            "Epoch 43/100\n",
            "\u001b[1m2164/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mse: 0.0013\n",
            "Epoch 43: val_loss did not improve from 0.00067\n",
            "\u001b[1m2181/2181\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - loss: 0.0013 - mse: 0.0013 - val_loss: 0.0015 - val_mse: 0.0015\n",
            "Epoch 43: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Performance: Training\n",
        "y_predtrain = model.predict([X_train],verbose=0)\n",
        "y_predtrain_SS = np.array(y_predtrain)\n",
        "\n",
        "train_r2_SS = r2_score(Y_train_SS, y_predtrain_SS)\n",
        "train_rmse_SS = np.sqrt(mean_squared_error(Y_train_SS, y_predtrain_SS))\n",
        "\n",
        "  # Model Performance: Validation\n",
        "y_predval = model.predict([X_val],verbose=0)\n",
        "y_predval_SS = np.array(y_predval)\n",
        "\n",
        "val_r2_SS = r2_score(Y_val_SS, y_predval_SS)\n",
        "val_rmse_SS = np.sqrt(mean_squared_error(Y_val_SS, y_predval_SS))\n",
        "\n",
        "  # Model Performance: Testing\n",
        "y_predtest = model.predict([x_test],verbose=0)\n",
        "y_predtest_SS = np.array(y_predtest)\n",
        "\n",
        "test_r2_SS = r2_score(y_test_SS, y_predtest_SS)\n",
        "test_rmse_SS = np.sqrt(mean_squared_error(y_test_SS, y_predtest_SS))\n",
        "\n",
        "  # Print R2 Results\n",
        "print(\"R2 scores: Train (SS) - %0.5f\" %(train_r2_SS))\n",
        "print(\"R2 scores: Validation (SS) - %0.5f\" %(val_r2_SS))\n",
        "print(\"R2 scores: Testing (SS) - %0.5f\" %(test_r2_SS))\n",
        "\n",
        "  # Print RSME Results\n",
        "print(\"RMSE scores: Train (SS) - %0.5f\" %(train_rmse_SS))\n",
        "print(\"RMSE scores: Validation (SS) - %0.5f\" %(val_rmse_SS))\n",
        "print(\"RMSE scores: Testing (SS) - %0.5f\" %(test_rmse_SS))"
      ],
      "metadata": {
        "id": "Bhgsw8lGkNg0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618a14b2-837d-458d-d091-999fe89953ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 scores: Train (SS) - 0.91806\n",
            "R2 scores: Validation (SS) - 0.91269\n",
            "R2 scores: Testing (SS) - 0.88080\n",
            "RMSE scores: Train (SS) - 0.03521\n",
            "RMSE scores: Validation (SS) - 0.03843\n",
            "RMSE scores: Testing (SS) - 0.04921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Extract Data\n",
        "# # SS\n",
        "# savetxt('Y_train_SS.csv', Y_train_SS, delimiter=',')\n",
        "# savetxt('Y_val_SS.csv', Y_val_SS, delimiter=',')\n",
        "# savetxt('y_test_SS.csv', y_test_SS, delimiter=',')\n",
        "# savetxt('y_predtrain_SS.csv', y_predtrain_SS, delimiter=',')\n",
        "# savetxt('y_predval_SS.csv', y_predval_SS, delimiter=',')\n",
        "# savetxt('y_predtest_SS.csv', y_predtest_SS, delimiter=',')"
      ],
      "metadata": {
        "id": "-uX7ngezkSfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download Data\n",
        "# # SS\n",
        "# files.download('Y_train_SS.csv')\n",
        "# files.download('Y_val_SS.csv')\n",
        "# files.download('y_test_SS.csv')\n",
        "# files.download('y_predtrain_SS.csv')\n",
        "# files.download('y_predval_SS.csv')\n",
        "# files.download('y_predtest_SS.csv')"
      ],
      "metadata": {
        "id": "1pR5pvhgkUZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJdd6oMInM1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}